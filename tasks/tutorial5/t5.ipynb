{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/oa321/mase/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Map: 100%|██████████| 50000/50000 [00:09<00:00, 5404.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4, 8],\n",
    "    \"num_heads\": [2, 4, 8, 16],\n",
    "    \"hidden_size\": [128, 192, 256, 384, 512],\n",
    "    \"intermediate_size\": [512, 768, 1024, 1536, 2048],\n",
    "    \"linear_layer_choices\" : [\n",
    "        nn.Linear,\n",
    "        Identity\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "\n",
    "def construct_model(trial):\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    for param in [\n",
    "        \"num_layers\",\n",
    "        \"num_heads\",\n",
    "        \"hidden_size\",\n",
    "        \"intermediate_size\"\n",
    "    ]:\n",
    "        chosen_idex = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        setattr(config, param, search_space[param][chosen_idex])\n",
    "\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            new_layer_cls = trial.suggest_categorical(\n",
    "                f\"{name}_type\",\n",
    "                search_space[\"linear_layer_choices\"],\n",
    "            )\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()\n",
    "                deepsetattr(trial_model, name, new_layer)\n",
    "            else:\n",
    "                raise ValueError(f\"Unkown layer type: {new_layer_cls}\")\n",
    "\n",
    "    return trial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_trainer\n",
    "\n",
    "def objective(trial):\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model = model,\n",
    "        tokenized_dataset = dataset,\n",
    "        tokenizer = tokenizer,\n",
    "        evaluate_metric = \"accuracy\",\n",
    "        num_train_epochs = 1\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "\n",
    "sampler = RandomSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-03 22:27:04,220] A new study created in memory with name: bert-tiny-nas-study\n",
      "/vol/bitbucket/oa321/mase/venv/lib/python3.11/site-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.linear.Linear'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/vol/bitbucket/oa321/mase/venv/lib/python3.11/site-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'chop.nn.modules.identity.Identity'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/vol/bitbucket/oa321/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.366400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-03 22:28:04,525] Trial 0 finished with value: 0.8552 and parameters: {'num_layers': 1, 'num_heads': 1, 'hidden_size': 1, 'intermediate_size': 4, 'bert.encoder.layer.0.attention.self.query_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.0.attention.self.key_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.0.attention.self.value_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.0.attention.output.dense_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.query_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.1.attention.self.key_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.value_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.output.dense_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.pooler.dense_type': <class 'torch.nn.modules.linear.Linear'>}. Best is trial 0 with value: 0.8552.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler\n",
    ")\n",
    "\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=1,\n",
    "    timeout=60*60*24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "model = study.best_trial.user_attrs[\"model\"].cpu()\n",
    "\n",
    "# print(Path.cwd())\n",
    "with open(f\"{Path.cwd()}/t5_best_model.pkl\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [-1.1689,  0.2944, -0.7488,  ..., -0.8390,  1.0188, -0.0816],\n",
      "         [-1.5564, -0.1051,  0.1067,  ...,  2.0985, -0.6764, -0.2505],\n",
      "         ...,\n",
      "         [-0.3092,  0.4680,  0.2085,  ..., -0.6054, -0.8652,  0.9209],\n",
      "         [ 0.2569,  0.2560,  0.5029,  ...,  0.9508, -1.4298,  0.6082],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]],\n",
      "\n",
      "        [[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [ 0.2781,  1.0137, -1.1776,  ...,  0.3920, -0.0946,  1.1161],\n",
      "         [-0.6903, -0.4475, -0.9203,  ...,  2.5490, -1.3861, -0.6113],\n",
      "         ...,\n",
      "         [ 0.9777,  0.6554, -0.5006,  ..., -0.2984, -1.0673, -0.3078],\n",
      "         [ 0.4563, -1.4165, -1.5023,  ...,  0.5032, -0.6009,  0.9690],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [-1.1689,  0.2944, -0.7488,  ..., -0.8390,  1.0188, -0.0816],\n",
      "         [-1.5564, -0.1051,  0.1067,  ...,  2.0985, -0.6764, -0.2505],\n",
      "         ...,\n",
      "         [-0.3092,  0.4680,  0.2085,  ..., -0.6054, -0.8652,  0.9209],\n",
      "         [ 0.2569,  0.2560,  0.5029,  ...,  0.9508, -1.4298,  0.6082],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]],\n",
      "\n",
      "        [[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [ 0.2781,  1.0137, -1.1776,  ...,  0.3920, -0.0946,  1.1161],\n",
      "         [-0.6903, -0.4475, -0.9203,  ...,  2.5490, -1.3861, -0.6113],\n",
      "         ...,\n",
      "         [ 0.9777,  0.6554, -0.5006,  ..., -0.2984, -1.0673, -0.3078],\n",
      "         [ 0.4563, -1.4165, -1.5023,  ...,  0.5032, -0.6009,  0.9690],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [-1.1689,  0.2944, -0.7488,  ..., -0.8390,  1.0188, -0.0816],\n",
      "         [-1.5564, -0.1051,  0.1067,  ...,  2.0985, -0.6764, -0.2505],\n",
      "         ...,\n",
      "         [-0.3092,  0.4680,  0.2085,  ..., -0.6054, -0.8652,  0.9209],\n",
      "         [ 0.2569,  0.2560,  0.5029,  ...,  0.9508, -1.4298,  0.6082],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]],\n",
      "\n",
      "        [[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [ 0.2781,  1.0137, -1.1776,  ...,  0.3920, -0.0946,  1.1161],\n",
      "         [-0.6903, -0.4475, -0.9203,  ...,  2.5490, -1.3861, -0.6113],\n",
      "         ...,\n",
      "         [ 0.9777,  0.6554, -0.5006,  ..., -0.2984, -1.0673, -0.3078],\n",
      "         [ 0.4563, -1.4165, -1.5023,  ...,  0.5032, -0.6009,  0.9690],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 1.0457, -0.4741, -0.1355,  ...,  0.9075, -0.9412,  0.1219],\n",
      "          [-0.7044, -1.2173,  0.2580,  ..., -0.2457,  0.8937,  0.6266]],\n",
      "\n",
      "         [[-1.1689,  0.2944, -0.7488,  ...,  0.2893, -2.4183,  0.1600],\n",
      "          [-0.6571, -1.5270,  0.2654,  ..., -0.8390,  1.0188, -0.0816]],\n",
      "\n",
      "         [[-1.5564, -0.1051,  0.1067,  ...,  1.0698, -0.9135, -0.5983],\n",
      "          [ 0.6932,  0.0643,  0.9559,  ...,  2.0985, -0.6764, -0.2505]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3092,  0.4680,  0.2085,  ..., -0.0713, -0.1215, -1.0890],\n",
      "          [-0.1908, -0.6099, -0.0672,  ..., -0.6054, -0.8652,  0.9209]],\n",
      "\n",
      "         [[ 0.2569,  0.2560,  0.5029,  ...,  2.2505, -1.0405, -2.3802],\n",
      "          [-0.9537, -1.0528,  0.1078,  ...,  0.9508, -1.4298,  0.6082]],\n",
      "\n",
      "         [[-0.9940, -0.6712, -0.7240,  ..., -0.1073, -1.3058, -0.0862],\n",
      "          [-0.1547, -2.2060, -1.5884,  ...,  1.4012, -0.6808,  2.0336]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0457, -0.4741, -0.1355,  ...,  0.9075, -0.9412,  0.1219],\n",
      "          [-0.7044, -1.2173,  0.2580,  ..., -0.2457,  0.8937,  0.6266]],\n",
      "\n",
      "         [[ 0.2781,  1.0137, -1.1776,  ..., -0.4869, -1.9216,  0.7228],\n",
      "          [-2.6968, -1.6928,  0.8601,  ...,  0.3920, -0.0946,  1.1161]],\n",
      "\n",
      "         [[-0.6903, -0.4475, -0.9203,  ...,  0.0129, -0.8336, -0.6805],\n",
      "          [ 0.9625,  0.0696,  0.7581,  ...,  2.5490, -1.3861, -0.6113]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9777,  0.6554, -0.5006,  ..., -0.3364, -1.3514,  0.0696],\n",
      "          [-1.0749,  0.2532, -0.3077,  ..., -0.2984, -1.0673, -0.3078]],\n",
      "\n",
      "         [[ 0.4563, -1.4165, -1.5023,  ...,  1.0727, -0.7566, -1.0054],\n",
      "          [-0.7266, -0.7323, -0.5847,  ...,  0.5032, -0.6009,  0.9690]],\n",
      "\n",
      "         [[-0.9940, -0.6712, -0.7240,  ..., -0.1073, -1.3058, -0.0862],\n",
      "          [-0.1547, -2.2060, -1.5884,  ...,  1.4012, -0.6808,  2.0336]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1762,  0.1719,  0.0064,  ...,  0.0130, -0.3567,  0.0574],\n",
      "         [-0.2274,  0.2443,  0.0136,  ..., -0.0743, -0.8807, -0.0652],\n",
      "         [-0.1350,  0.3300, -0.1783,  ...,  0.0236, -0.4354, -0.0310],\n",
      "         ...,\n",
      "         [ 0.0077,  0.4290, -0.2345,  ...,  0.0767, -0.9732, -0.4375],\n",
      "         [ 0.1988,  0.3692, -0.4656,  ...,  0.4054,  0.0343, -0.1894],\n",
      "         [ 0.0239,  0.5000, -0.1162,  ...,  0.0935, -0.8410,  0.2208]],\n",
      "\n",
      "        [[ 0.1762,  0.1719,  0.0064,  ...,  0.0130, -0.3567,  0.0574],\n",
      "         [-0.3551,  0.2858, -0.0870,  ..., -0.0170, -0.6313, -0.2855],\n",
      "         [ 0.2308,  0.0690, -0.6381,  ...,  0.0223, -0.5903, -0.3842],\n",
      "         ...,\n",
      "         [ 0.2264,  0.3882, -0.0730,  ..., -0.0347, -0.5468, -0.4514],\n",
      "         [ 0.0463,  0.2498, -0.1069,  ...,  0.7363,  0.1516, -0.3530],\n",
      "         [ 0.0239,  0.5000, -0.1162,  ...,  0.0935, -0.8410,  0.2208]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1762,  0.1719,  0.0064,  ...,  0.0130, -0.3567,  0.0574],\n",
      "         [-0.2274,  0.2443,  0.0136,  ..., -0.0743, -0.8807, -0.0652],\n",
      "         [-0.1350,  0.3300, -0.1783,  ...,  0.0236, -0.4354, -0.0310],\n",
      "         ...,\n",
      "         [ 0.0077,  0.4290, -0.2345,  ...,  0.0767, -0.9732, -0.4375],\n",
      "         [ 0.1988,  0.3692, -0.4656,  ...,  0.4054,  0.0343, -0.1894],\n",
      "         [ 0.0239,  0.5000, -0.1162,  ...,  0.0935, -0.8410,  0.2208]],\n",
      "\n",
      "        [[ 0.1762,  0.1719,  0.0064,  ...,  0.0130, -0.3567,  0.0574],\n",
      "         [-0.3551,  0.2858, -0.0870,  ..., -0.0170, -0.6313, -0.2855],\n",
      "         [ 0.2308,  0.0690, -0.6381,  ...,  0.0223, -0.5903, -0.3842],\n",
      "         ...,\n",
      "         [ 0.2264,  0.3882, -0.0730,  ..., -0.0347, -0.5468, -0.4514],\n",
      "         [ 0.0463,  0.2498, -0.1069,  ...,  0.7363,  0.1516, -0.3530],\n",
      "         [ 0.0239,  0.5000, -0.1162,  ...,  0.0935, -0.8410,  0.2208]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1762,  0.1719,  0.0064,  ...,  0.0637,  0.4409,  0.2111],\n",
      "          [-0.0199,  0.0996, -0.1042,  ...,  0.0130, -0.3567,  0.0574]],\n",
      "\n",
      "         [[-0.2274,  0.2443,  0.0136,  ...,  0.0394,  0.6110,  0.4616],\n",
      "          [-0.1441,  0.1265,  0.0714,  ..., -0.0743, -0.8807, -0.0652]],\n",
      "\n",
      "         [[-0.1350,  0.3300, -0.1783,  ...,  0.1399, -0.0547, -0.4219],\n",
      "          [-0.1528,  0.5376,  0.2485,  ...,  0.0236, -0.4354, -0.0310]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0077,  0.4290, -0.2345,  ..., -0.4736,  0.5047,  0.3791],\n",
      "          [-0.1096,  0.4375,  0.4103,  ...,  0.0767, -0.9732, -0.4375]],\n",
      "\n",
      "         [[ 0.1988,  0.3692, -0.4656,  ..., -0.0150,  0.0716,  0.2665],\n",
      "          [ 0.4285, -0.1600,  0.0800,  ...,  0.4054,  0.0343, -0.1894]],\n",
      "\n",
      "         [[ 0.0239,  0.5000, -0.1162,  ..., -0.2387,  1.0241, -0.2032],\n",
      "          [-0.1137, -0.0679,  0.0740,  ...,  0.0935, -0.8410,  0.2208]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1762,  0.1719,  0.0064,  ...,  0.0637,  0.4409,  0.2111],\n",
      "          [-0.0199,  0.0996, -0.1042,  ...,  0.0130, -0.3567,  0.0574]],\n",
      "\n",
      "         [[-0.3551,  0.2858, -0.0870,  ...,  0.0402,  0.3937,  0.5235],\n",
      "          [ 0.2211, -0.1542, -0.2043,  ..., -0.0170, -0.6313, -0.2855]],\n",
      "\n",
      "         [[ 0.2308,  0.0690, -0.6381,  ...,  0.2271,  0.0876, -0.1928],\n",
      "          [-0.0541,  0.2942, -0.2584,  ...,  0.0223, -0.5903, -0.3842]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2264,  0.3882, -0.0730,  ..., -0.0156,  0.4362,  0.2507],\n",
      "          [-0.2743,  0.4989,  0.1702,  ..., -0.0347, -0.5468, -0.4514]],\n",
      "\n",
      "         [[ 0.0463,  0.2498, -0.1069,  ...,  0.0624,  0.1012,  0.4281],\n",
      "          [ 0.3409, -0.0170, -0.3453,  ...,  0.7363,  0.1516, -0.3530]],\n",
      "\n",
      "         [[ 0.0239,  0.5000, -0.1162,  ..., -0.2387,  1.0241, -0.2032],\n",
      "          [-0.1137, -0.0679,  0.0740,  ...,  0.0935, -0.8410,  0.2208]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [-1.1689,  0.2944, -0.7488,  ..., -0.8390,  1.0188, -0.0816],\n",
      "         [-1.5564, -0.1051,  0.1067,  ...,  2.0985, -0.6764, -0.2505],\n",
      "         ...,\n",
      "         [-0.3092,  0.4680,  0.2085,  ..., -0.6054, -0.8652,  0.9209],\n",
      "         [ 0.2569,  0.2560,  0.5029,  ...,  0.9508, -1.4298,  0.6082],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]],\n",
      "\n",
      "        [[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [ 0.2781,  1.0137, -1.1776,  ...,  0.3920, -0.0946,  1.1161],\n",
      "         [-0.6903, -0.4475, -0.9203,  ...,  2.5490, -1.3861, -0.6113],\n",
      "         ...,\n",
      "         [ 0.9777,  0.6554, -0.5006,  ..., -0.2984, -1.0673, -0.3078],\n",
      "         [ 0.4563, -1.4165, -1.5023,  ...,  0.5032, -0.6009,  0.9690],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [-1.1689,  0.2944, -0.7488,  ..., -0.8390,  1.0188, -0.0816],\n",
      "         [-1.5564, -0.1051,  0.1067,  ...,  2.0985, -0.6764, -0.2505],\n",
      "         ...,\n",
      "         [-0.3092,  0.4680,  0.2085,  ..., -0.6054, -0.8652,  0.9209],\n",
      "         [ 0.2569,  0.2560,  0.5029,  ...,  0.9508, -1.4298,  0.6082],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]],\n",
      "\n",
      "        [[ 1.0457, -0.4741, -0.1355,  ..., -0.2457,  0.8937,  0.6266],\n",
      "         [ 0.2781,  1.0137, -1.1776,  ...,  0.3920, -0.0946,  1.1161],\n",
      "         [-0.6903, -0.4475, -0.9203,  ...,  2.5490, -1.3861, -0.6113],\n",
      "         ...,\n",
      "         [ 0.9777,  0.6554, -0.5006,  ..., -0.2984, -1.0673, -0.3078],\n",
      "         [ 0.4563, -1.4165, -1.5023,  ...,  0.5032, -0.6009,  0.9690],\n",
      "         [-0.9940, -0.6712, -0.7240,  ...,  1.4012, -0.6808,  2.0336]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 1.0457, -0.4741, -0.1355,  ...,  0.9075, -0.9412,  0.1219],\n",
      "          [-0.7044, -1.2173,  0.2580,  ..., -0.2457,  0.8937,  0.6266]],\n",
      "\n",
      "         [[-1.1689,  0.2944, -0.7488,  ...,  0.2893, -2.4183,  0.1600],\n",
      "          [-0.6571, -1.5270,  0.2654,  ..., -0.8390,  1.0188, -0.0816]],\n",
      "\n",
      "         [[-1.5564, -0.1051,  0.1067,  ...,  1.0698, -0.9135, -0.5983],\n",
      "          [ 0.6932,  0.0643,  0.9559,  ...,  2.0985, -0.6764, -0.2505]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3092,  0.4680,  0.2085,  ..., -0.0713, -0.1215, -1.0890],\n",
      "          [-0.1908, -0.6099, -0.0672,  ..., -0.6054, -0.8652,  0.9209]],\n",
      "\n",
      "         [[ 0.2569,  0.2560,  0.5029,  ...,  2.2505, -1.0405, -2.3802],\n",
      "          [-0.9537, -1.0528,  0.1078,  ...,  0.9508, -1.4298,  0.6082]],\n",
      "\n",
      "         [[-0.9940, -0.6712, -0.7240,  ..., -0.1073, -1.3058, -0.0862],\n",
      "          [-0.1547, -2.2060, -1.5884,  ...,  1.4012, -0.6808,  2.0336]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0457, -0.4741, -0.1355,  ...,  0.9075, -0.9412,  0.1219],\n",
      "          [-0.7044, -1.2173,  0.2580,  ..., -0.2457,  0.8937,  0.6266]],\n",
      "\n",
      "         [[ 0.2781,  1.0137, -1.1776,  ..., -0.4869, -1.9216,  0.7228],\n",
      "          [-2.6968, -1.6928,  0.8601,  ...,  0.3920, -0.0946,  1.1161]],\n",
      "\n",
      "         [[-0.6903, -0.4475, -0.9203,  ...,  0.0129, -0.8336, -0.6805],\n",
      "          [ 0.9625,  0.0696,  0.7581,  ...,  2.5490, -1.3861, -0.6113]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9777,  0.6554, -0.5006,  ..., -0.3364, -1.3514,  0.0696],\n",
      "          [-1.0749,  0.2532, -0.3077,  ..., -0.2984, -1.0673, -0.3078]],\n",
      "\n",
      "         [[ 0.4563, -1.4165, -1.5023,  ...,  1.0727, -0.7566, -1.0054],\n",
      "          [-0.7266, -0.7323, -0.5847,  ...,  0.5032, -0.6009,  0.9690]],\n",
      "\n",
      "         [[-0.9940, -0.6712, -0.7240,  ..., -0.1073, -1.3058, -0.0862],\n",
      "          [-0.1547, -2.2060, -1.5884,  ...,  1.4012, -0.6808,  2.0336]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.7143,  0.2285, -0.4865,  ...,  0.8542, -0.7840, -0.9974],\n",
      "          [-0.5764,  0.2073, -0.5300,  ...,  0.7330, -0.8655, -0.8670],\n",
      "          [-0.6483,  0.2013, -0.4987,  ...,  0.7429, -0.8377, -0.8369],\n",
      "          ...,\n",
      "          [-0.4809,  0.1688, -0.3880,  ...,  0.8262, -0.8571, -0.9818],\n",
      "          [-0.5420,  0.2107, -0.5384,  ...,  0.6773, -0.8093, -0.8363],\n",
      "          [-0.4414,  0.1897, -0.5026,  ...,  0.6807, -0.9429, -0.8261]],\n",
      "\n",
      "         [[-0.5953, -1.0574, -0.5726,  ...,  0.9325,  0.1216,  0.7558],\n",
      "          [-0.6471, -1.0936, -0.3175,  ...,  0.8014,  0.1152,  0.9313],\n",
      "          [-0.6240, -0.9599, -0.1172,  ...,  0.7532,  0.0740,  0.9044],\n",
      "          ...,\n",
      "          [-0.5248, -1.0448, -0.1073,  ...,  0.7310, -0.0123,  0.7993],\n",
      "          [-0.5835, -1.1029, -0.2935,  ...,  0.7926,  0.0444,  0.9826],\n",
      "          [-0.6580, -1.1562, -0.3383,  ...,  0.7265,  0.0497,  0.8540]]],\n",
      "\n",
      "\n",
      "        [[[-0.5207,  0.0406, -0.4281,  ...,  0.5738, -0.6700,  0.1643],\n",
      "          [-0.3266, -0.0453, -0.4725,  ...,  0.5721, -0.8307, -0.0178],\n",
      "          [-0.3793, -0.0305, -0.5102,  ...,  0.4973, -0.7588, -0.0012],\n",
      "          ...,\n",
      "          [-0.3558, -0.0166, -0.4778,  ...,  0.4899, -0.7876,  0.0744],\n",
      "          [-0.4286,  0.0035, -0.3824,  ...,  0.5310, -0.7373,  0.1828],\n",
      "          [-0.2963,  0.0526, -0.4729,  ...,  0.5018, -0.9123, -0.0627]],\n",
      "\n",
      "         [[-0.3882, -0.3981, -0.7103,  ...,  0.9500,  0.2292,  1.0032],\n",
      "          [-0.4980, -0.4838, -0.6066,  ...,  0.8725, -0.0329,  0.8137],\n",
      "          [-0.4550, -0.3866, -0.5910,  ...,  0.8569, -0.0883,  0.7372],\n",
      "          ...,\n",
      "          [-0.5244, -0.4274, -0.5618,  ...,  0.7600, -0.1097,  0.7061],\n",
      "          [-0.5488, -0.4179, -0.6518,  ...,  0.8340, -0.0798,  0.7794],\n",
      "          [-0.5581, -0.4852, -0.5400,  ...,  0.8326, -0.1020,  0.7410]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.7143,  0.2285, -0.4865,  ...,  0.8542, -0.7840, -0.9974],\n",
      "          [-0.5953, -1.0574, -0.5726,  ...,  0.9325,  0.1216,  0.7558]],\n",
      "\n",
      "         [[-0.5764,  0.2073, -0.5300,  ...,  0.7330, -0.8655, -0.8670],\n",
      "          [-0.6471, -1.0936, -0.3175,  ...,  0.8014,  0.1152,  0.9313]],\n",
      "\n",
      "         [[-0.6483,  0.2013, -0.4987,  ...,  0.7429, -0.8377, -0.8369],\n",
      "          [-0.6240, -0.9599, -0.1172,  ...,  0.7532,  0.0740,  0.9044]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4809,  0.1688, -0.3880,  ...,  0.8262, -0.8571, -0.9818],\n",
      "          [-0.5248, -1.0448, -0.1073,  ...,  0.7310, -0.0123,  0.7993]],\n",
      "\n",
      "         [[-0.5420,  0.2107, -0.5384,  ...,  0.6773, -0.8093, -0.8363],\n",
      "          [-0.5835, -1.1029, -0.2935,  ...,  0.7926,  0.0444,  0.9826]],\n",
      "\n",
      "         [[-0.4414,  0.1897, -0.5026,  ...,  0.6807, -0.9429, -0.8261],\n",
      "          [-0.6580, -1.1562, -0.3383,  ...,  0.7265,  0.0497,  0.8540]]],\n",
      "\n",
      "\n",
      "        [[[-0.5207,  0.0406, -0.4281,  ...,  0.5738, -0.6700,  0.1643],\n",
      "          [-0.3882, -0.3981, -0.7103,  ...,  0.9500,  0.2292,  1.0032]],\n",
      "\n",
      "         [[-0.3266, -0.0453, -0.4725,  ...,  0.5721, -0.8307, -0.0178],\n",
      "          [-0.4980, -0.4838, -0.6066,  ...,  0.8725, -0.0329,  0.8137]],\n",
      "\n",
      "         [[-0.3793, -0.0305, -0.5102,  ...,  0.4973, -0.7588, -0.0012],\n",
      "          [-0.4550, -0.3866, -0.5910,  ...,  0.8569, -0.0883,  0.7372]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3558, -0.0166, -0.4778,  ...,  0.4899, -0.7876,  0.0744],\n",
      "          [-0.5244, -0.4274, -0.5618,  ...,  0.7600, -0.1097,  0.7061]],\n",
      "\n",
      "         [[-0.4286,  0.0035, -0.3824,  ...,  0.5310, -0.7373,  0.1828],\n",
      "          [-0.5488, -0.4179, -0.6518,  ...,  0.8340, -0.0798,  0.7794]],\n",
      "\n",
      "         [[-0.2963,  0.0526, -0.4729,  ...,  0.5018, -0.9123, -0.0627],\n",
      "          [-0.5581, -0.4852, -0.5400,  ...,  0.8326, -0.1020,  0.7410]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.1501, -0.0760, -0.4481,  ...,  0.8951,  1.0798,  1.1514],\n",
      "         [-1.4586,  0.2191, -0.7155,  ..., -0.0509,  0.7501,  0.7306],\n",
      "         [-1.8659, -0.3074, -0.0596,  ...,  2.2889, -0.2756,  0.4545],\n",
      "         ...,\n",
      "         [-0.5473,  0.3592, -0.2195,  ...,  0.0569, -0.8207,  1.2796],\n",
      "         [-0.0364,  0.4349, -0.0483,  ...,  1.4250, -1.1634,  1.1405],\n",
      "         [-1.1089, -0.7119, -0.7444,  ...,  1.6021, -0.4632,  2.1589]],\n",
      "\n",
      "        [[ 0.1825, -0.3662, -0.2765,  ...,  0.8420,  1.2524,  1.2455],\n",
      "         [ 0.0335,  0.5236, -0.9490,  ...,  0.9959, -0.2515,  1.5763],\n",
      "         [-0.8423, -0.6972, -0.9051,  ...,  2.6278, -1.0854, -0.0061],\n",
      "         ...,\n",
      "         [ 0.4644,  0.2643, -0.8147,  ...,  0.2508, -0.8680,  0.1852],\n",
      "         [-0.0356, -1.4995, -1.3971,  ...,  1.0448, -0.4089,  1.3863],\n",
      "         [-1.1003, -0.9609, -0.6742,  ...,  1.7294, -0.5269,  2.1107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 4.3834e-01, -2.3278e-01, -3.3664e-02,  ...,  9.5781e-01,\n",
      "           1.3478e+00, -1.0991e+00],\n",
      "         [ 1.6467e-01, -5.0035e-01,  7.8192e-02,  ...,  6.6227e-01,\n",
      "           6.9849e-01, -1.2172e+00],\n",
      "         [-7.2805e-02, -6.7712e-01,  2.9913e-01,  ...,  8.3041e-01,\n",
      "           9.6423e-01, -1.0916e+00],\n",
      "         ...,\n",
      "         [ 1.3368e-01, -3.1730e-01,  6.1444e-02,  ...,  4.6651e-01,\n",
      "           8.8174e-01, -1.0130e+00],\n",
      "         [ 3.3276e-01, -6.5325e-03, -6.5791e-02,  ...,  4.9534e-01,\n",
      "           8.4640e-01, -9.2231e-01],\n",
      "         [ 2.6097e-01, -2.1552e-01,  8.9441e-02,  ...,  6.7177e-01,\n",
      "           6.2520e-01, -6.2364e-01]],\n",
      "\n",
      "        [[ 3.4026e-01, -2.1065e-01, -1.0819e-03,  ...,  1.1489e+00,\n",
      "           1.5171e+00, -9.5518e-01],\n",
      "         [ 7.4885e-03, -4.0612e-01,  6.0251e-02,  ...,  6.7288e-01,\n",
      "           1.3457e+00, -6.3349e-01],\n",
      "         [ 3.5461e-01, -6.1985e-01, -4.1274e-02,  ...,  6.0598e-01,\n",
      "           1.0717e+00, -1.0523e+00],\n",
      "         ...,\n",
      "         [-6.8007e-02, -1.5223e-01, -8.0316e-02,  ...,  7.9604e-01,\n",
      "           1.1183e+00, -8.2233e-01],\n",
      "         [ 5.5587e-01, -2.1024e-01,  5.4427e-02,  ...,  9.4150e-01,\n",
      "           1.2326e+00, -6.2122e-01],\n",
      "         [ 2.3663e-01, -2.5142e-01,  9.5282e-02,  ...,  8.2686e-01,\n",
      "           7.6918e-01, -5.2293e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 4.3834e-01, -2.3278e-01, -3.3664e-02,  ...,  9.5781e-01,\n",
      "           1.3478e+00, -1.0991e+00],\n",
      "         [ 1.6467e-01, -5.0035e-01,  7.8192e-02,  ...,  6.6227e-01,\n",
      "           6.9849e-01, -1.2172e+00],\n",
      "         [-7.2805e-02, -6.7712e-01,  2.9913e-01,  ...,  8.3041e-01,\n",
      "           9.6423e-01, -1.0916e+00],\n",
      "         ...,\n",
      "         [ 1.3368e-01, -3.1730e-01,  6.1444e-02,  ...,  4.6651e-01,\n",
      "           8.8174e-01, -1.0130e+00],\n",
      "         [ 3.3276e-01, -6.5325e-03, -6.5791e-02,  ...,  4.9534e-01,\n",
      "           8.4640e-01, -9.2231e-01],\n",
      "         [ 2.6097e-01, -2.1552e-01,  8.9441e-02,  ...,  6.7177e-01,\n",
      "           6.2520e-01, -6.2364e-01]],\n",
      "\n",
      "        [[ 3.4026e-01, -2.1065e-01, -1.0819e-03,  ...,  1.1489e+00,\n",
      "           1.5171e+00, -9.5518e-01],\n",
      "         [ 7.4885e-03, -4.0612e-01,  6.0251e-02,  ...,  6.7288e-01,\n",
      "           1.3457e+00, -6.3349e-01],\n",
      "         [ 3.5461e-01, -6.1985e-01, -4.1274e-02,  ...,  6.0598e-01,\n",
      "           1.0717e+00, -1.0523e+00],\n",
      "         ...,\n",
      "         [-6.8007e-02, -1.5223e-01, -8.0316e-02,  ...,  7.9604e-01,\n",
      "           1.1183e+00, -8.2233e-01],\n",
      "         [ 5.5587e-01, -2.1024e-01,  5.4427e-02,  ...,  9.4150e-01,\n",
      "           1.2326e+00, -6.2122e-01],\n",
      "         [ 2.3663e-01, -2.5142e-01,  9.5282e-02,  ...,  8.2686e-01,\n",
      "           7.6918e-01, -5.2293e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 4.3834e-01, -2.3278e-01, -3.3664e-02,  ...,  1.8340e+00,\n",
      "            1.0158e+00, -8.4530e-01],\n",
      "          [ 2.3341e-02,  1.2646e+00, -9.9429e-01,  ...,  9.5781e-01,\n",
      "            1.3478e+00, -1.0991e+00]],\n",
      "\n",
      "         [[ 1.6467e-01, -5.0035e-01,  7.8192e-02,  ...,  1.2182e+00,\n",
      "            1.8291e-01, -3.0695e-01],\n",
      "          [ 5.0510e-01,  1.5126e-01, -6.9005e-01,  ...,  6.6227e-01,\n",
      "            6.9849e-01, -1.2172e+00]],\n",
      "\n",
      "         [[-7.2805e-02, -6.7712e-01,  2.9913e-01,  ...,  1.1075e+00,\n",
      "            4.2252e-01, -5.2087e-01],\n",
      "          [-4.8261e-02,  5.7387e-01, -6.0756e-01,  ...,  8.3041e-01,\n",
      "            9.6423e-01, -1.0916e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3368e-01, -3.1730e-01,  6.1444e-02,  ...,  1.0435e+00,\n",
      "            1.2690e-01, -4.9257e-01],\n",
      "          [ 1.5008e-01,  5.3597e-01, -6.3702e-01,  ...,  4.6651e-01,\n",
      "            8.8174e-01, -1.0130e+00]],\n",
      "\n",
      "         [[ 3.3276e-01, -6.5325e-03, -6.5791e-02,  ...,  1.1870e+00,\n",
      "            7.0852e-01, -5.5097e-01],\n",
      "          [ 2.6502e-01,  7.6145e-01, -4.9666e-01,  ...,  4.9534e-01,\n",
      "            8.4640e-01, -9.2231e-01]],\n",
      "\n",
      "         [[ 2.6097e-01, -2.1552e-01,  8.9441e-02,  ...,  1.1623e+00,\n",
      "            1.4961e-01, -4.0857e-01],\n",
      "          [ 1.4442e-01,  6.0257e-01, -6.2137e-01,  ...,  6.7177e-01,\n",
      "            6.2520e-01, -6.2364e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4026e-01, -2.1065e-01, -1.0819e-03,  ...,  1.6635e+00,\n",
      "            9.5086e-01, -6.1189e-01],\n",
      "          [-6.4986e-02,  1.2882e+00, -9.4993e-01,  ...,  1.1489e+00,\n",
      "            1.5171e+00, -9.5518e-01]],\n",
      "\n",
      "         [[ 7.4885e-03, -4.0612e-01,  6.0251e-02,  ...,  9.9260e-01,\n",
      "            6.5912e-01,  1.6204e-01],\n",
      "          [ 4.7840e-01,  3.4084e-01, -5.4047e-01,  ...,  6.7288e-01,\n",
      "            1.3457e+00, -6.3349e-01]],\n",
      "\n",
      "         [[ 3.5461e-01, -6.1985e-01, -4.1274e-02,  ...,  1.3201e+00,\n",
      "            3.7596e-01, -3.6094e-01],\n",
      "          [-6.1246e-02,  5.6848e-01, -2.6155e-01,  ...,  6.0598e-01,\n",
      "            1.0717e+00, -1.0523e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.8007e-02, -1.5223e-01, -8.0316e-02,  ...,  7.8978e-01,\n",
      "            4.6412e-01, -1.5190e-01],\n",
      "          [ 4.9766e-03,  2.8896e-01, -3.1499e-01,  ...,  7.9604e-01,\n",
      "            1.1183e+00, -8.2233e-01]],\n",
      "\n",
      "         [[ 5.5587e-01, -2.1024e-01,  5.4427e-02,  ...,  1.1209e+00,\n",
      "            5.1556e-01, -4.8615e-01],\n",
      "          [ 2.7019e-01,  8.0997e-01, -5.2268e-01,  ...,  9.4150e-01,\n",
      "            1.2326e+00, -6.2122e-01]],\n",
      "\n",
      "         [[ 2.3663e-01, -2.5142e-01,  9.5282e-02,  ...,  1.0784e+00,\n",
      "            1.3457e-01, -2.4603e-01],\n",
      "          [ 7.9961e-02,  6.1485e-01, -5.9341e-01,  ...,  8.2686e-01,\n",
      "            7.6918e-01, -5.2293e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1501, -0.0760, -0.4481,  ...,  0.8951,  1.0798,  1.1514],\n",
      "         [-1.4586,  0.2191, -0.7155,  ..., -0.0509,  0.7501,  0.7306],\n",
      "         [-1.8659, -0.3074, -0.0596,  ...,  2.2889, -0.2756,  0.4545],\n",
      "         ...,\n",
      "         [-0.5473,  0.3592, -0.2195,  ...,  0.0569, -0.8207,  1.2796],\n",
      "         [-0.0364,  0.4349, -0.0483,  ...,  1.4250, -1.1634,  1.1405],\n",
      "         [-1.1089, -0.7119, -0.7444,  ...,  1.6021, -0.4632,  2.1589]],\n",
      "\n",
      "        [[ 0.1825, -0.3662, -0.2765,  ...,  0.8420,  1.2524,  1.2455],\n",
      "         [ 0.0335,  0.5236, -0.9490,  ...,  0.9959, -0.2515,  1.5763],\n",
      "         [-0.8423, -0.6972, -0.9051,  ...,  2.6278, -1.0854, -0.0061],\n",
      "         ...,\n",
      "         [ 0.4644,  0.2643, -0.8147,  ...,  0.2508, -0.8680,  0.1852],\n",
      "         [-0.0356, -1.4995, -1.3971,  ...,  1.0448, -0.4089,  1.3863],\n",
      "         [-1.1003, -0.9609, -0.6742,  ...,  1.7294, -0.5269,  2.1107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.1501, -0.0760, -0.4481,  ...,  0.8951,  1.0798,  1.1514],\n",
      "         [-1.4586,  0.2191, -0.7155,  ..., -0.0509,  0.7501,  0.7306],\n",
      "         [-1.8659, -0.3074, -0.0596,  ...,  2.2889, -0.2756,  0.4545],\n",
      "         ...,\n",
      "         [-0.5473,  0.3592, -0.2195,  ...,  0.0569, -0.8207,  1.2796],\n",
      "         [-0.0364,  0.4349, -0.0483,  ...,  1.4250, -1.1634,  1.1405],\n",
      "         [-1.1089, -0.7119, -0.7444,  ...,  1.6021, -0.4632,  2.1589]],\n",
      "\n",
      "        [[ 0.1825, -0.3662, -0.2765,  ...,  0.8420,  1.2524,  1.2455],\n",
      "         [ 0.0335,  0.5236, -0.9490,  ...,  0.9959, -0.2515,  1.5763],\n",
      "         [-0.8423, -0.6972, -0.9051,  ...,  2.6278, -1.0854, -0.0061],\n",
      "         ...,\n",
      "         [ 0.4644,  0.2643, -0.8147,  ...,  0.2508, -0.8680,  0.1852],\n",
      "         [-0.0356, -1.4995, -1.3971,  ...,  1.0448, -0.4089,  1.3863],\n",
      "         [-1.1003, -0.9609, -0.6742,  ...,  1.7294, -0.5269,  2.1107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.1501, -0.0760, -0.4481,  ...,  1.2746, -1.1977, -0.3888],\n",
      "          [-0.6588, -1.5850,  0.4474,  ...,  0.8951,  1.0798,  1.1514]],\n",
      "\n",
      "         [[-1.4586,  0.2191, -0.7155,  ...,  0.7404, -2.2938, -0.2041],\n",
      "          [-0.3517, -1.8668,  0.5951,  ..., -0.0509,  0.7501,  0.7306]],\n",
      "\n",
      "         [[-1.8659, -0.3074, -0.0596,  ...,  1.2153, -0.9887, -0.9609],\n",
      "          [ 0.5658, -0.5984,  1.1122,  ...,  2.2889, -0.2756,  0.4545]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5473,  0.3592, -0.2195,  ...,  0.4929, -0.3925, -1.0144],\n",
      "          [ 0.1937, -1.1010,  0.6020,  ...,  0.0569, -0.8207,  1.2796]],\n",
      "\n",
      "         [[-0.0364,  0.4349, -0.0483,  ...,  2.1265, -1.1460, -1.8740],\n",
      "          [-0.3481, -1.3077,  0.6844,  ...,  1.4250, -1.1634,  1.1405]],\n",
      "\n",
      "         [[-1.1089, -0.7119, -0.7444,  ...,  0.2793, -1.4160, -0.2804],\n",
      "          [ 0.2041, -2.3190, -0.6957,  ...,  1.6021, -0.4632,  2.1589]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1825, -0.3662, -0.2765,  ...,  1.0684, -1.0255,  0.4294],\n",
      "          [-0.6892, -1.1335,  0.1937,  ...,  0.8420,  1.2524,  1.2455]],\n",
      "\n",
      "         [[ 0.0335,  0.5236, -0.9490,  ..., -0.1174, -1.8636,  0.8884],\n",
      "          [-2.2064, -1.6562,  0.7537,  ...,  0.9959, -0.2515,  1.5763]],\n",
      "\n",
      "         [[-0.8423, -0.6972, -0.9051,  ...,  0.2931, -0.7744, -0.1897],\n",
      "          [ 0.9456,  0.0344,  0.6242,  ...,  2.6278, -1.0854, -0.0061]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4644,  0.2643, -0.8147,  ...,  0.0692, -1.1281,  0.5858],\n",
      "          [-0.8043,  0.0484, -0.1762,  ...,  0.2508, -0.8680,  0.1852]],\n",
      "\n",
      "         [[-0.0356, -1.4995, -1.3971,  ...,  1.4830, -0.6459, -0.3064],\n",
      "          [-0.4609, -0.5825, -0.4957,  ...,  1.0448, -0.4089,  1.3863]],\n",
      "\n",
      "         [[-1.1003, -0.9609, -0.6742,  ...,  0.1590, -1.3803,  0.2803],\n",
      "          [ 0.1687, -1.9053, -1.0013,  ...,  1.7294, -0.5269,  2.1107]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.1501, -0.0760, -0.4481,  ...,  0.8951,  1.0798,  1.1514],\n",
      "         [-1.4586,  0.2191, -0.7155,  ..., -0.0509,  0.7501,  0.7306],\n",
      "         [-1.8659, -0.3074, -0.0596,  ...,  2.2889, -0.2756,  0.4545],\n",
      "         ...,\n",
      "         [-0.5473,  0.3592, -0.2195,  ...,  0.0569, -0.8207,  1.2796],\n",
      "         [-0.0364,  0.4349, -0.0483,  ...,  1.4250, -1.1634,  1.1405],\n",
      "         [-1.1089, -0.7119, -0.7444,  ...,  1.6021, -0.4632,  2.1589]],\n",
      "\n",
      "        [[ 0.1825, -0.3662, -0.2765,  ...,  0.8420,  1.2524,  1.2455],\n",
      "         [ 0.0335,  0.5236, -0.9490,  ...,  0.9959, -0.2515,  1.5763],\n",
      "         [-0.8423, -0.6972, -0.9051,  ...,  2.6278, -1.0854, -0.0061],\n",
      "         ...,\n",
      "         [ 0.4644,  0.2643, -0.8147,  ...,  0.2508, -0.8680,  0.1852],\n",
      "         [-0.0356, -1.4995, -1.3971,  ...,  1.0448, -0.4089,  1.3863],\n",
      "         [-1.1003, -0.9609, -0.6742,  ...,  1.7294, -0.5269,  2.1107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.1501, -0.0760, -0.4481,  ...,  0.8951,  1.0798,  1.1514],\n",
      "         [-1.4586,  0.2191, -0.7155,  ..., -0.0509,  0.7501,  0.7306],\n",
      "         [-1.8659, -0.3074, -0.0596,  ...,  2.2889, -0.2756,  0.4545],\n",
      "         ...,\n",
      "         [-0.5473,  0.3592, -0.2195,  ...,  0.0569, -0.8207,  1.2796],\n",
      "         [-0.0364,  0.4349, -0.0483,  ...,  1.4250, -1.1634,  1.1405],\n",
      "         [-1.1089, -0.7119, -0.7444,  ...,  1.6021, -0.4632,  2.1589]],\n",
      "\n",
      "        [[ 0.1825, -0.3662, -0.2765,  ...,  0.8420,  1.2524,  1.2455],\n",
      "         [ 0.0335,  0.5236, -0.9490,  ...,  0.9959, -0.2515,  1.5763],\n",
      "         [-0.8423, -0.6972, -0.9051,  ...,  2.6278, -1.0854, -0.0061],\n",
      "         ...,\n",
      "         [ 0.4644,  0.2643, -0.8147,  ...,  0.2508, -0.8680,  0.1852],\n",
      "         [-0.0356, -1.4995, -1.3971,  ...,  1.0448, -0.4089,  1.3863],\n",
      "         [-1.1003, -0.9609, -0.6742,  ...,  1.7294, -0.5269,  2.1107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.1501, -0.0760, -0.4481,  ...,  1.2746, -1.1977, -0.3888],\n",
      "          [-0.6588, -1.5850,  0.4474,  ...,  0.8951,  1.0798,  1.1514]],\n",
      "\n",
      "         [[-1.4586,  0.2191, -0.7155,  ...,  0.7404, -2.2938, -0.2041],\n",
      "          [-0.3517, -1.8668,  0.5951,  ..., -0.0509,  0.7501,  0.7306]],\n",
      "\n",
      "         [[-1.8659, -0.3074, -0.0596,  ...,  1.2153, -0.9887, -0.9609],\n",
      "          [ 0.5658, -0.5984,  1.1122,  ...,  2.2889, -0.2756,  0.4545]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5473,  0.3592, -0.2195,  ...,  0.4929, -0.3925, -1.0144],\n",
      "          [ 0.1937, -1.1010,  0.6020,  ...,  0.0569, -0.8207,  1.2796]],\n",
      "\n",
      "         [[-0.0364,  0.4349, -0.0483,  ...,  2.1265, -1.1460, -1.8740],\n",
      "          [-0.3481, -1.3077,  0.6844,  ...,  1.4250, -1.1634,  1.1405]],\n",
      "\n",
      "         [[-1.1089, -0.7119, -0.7444,  ...,  0.2793, -1.4160, -0.2804],\n",
      "          [ 0.2041, -2.3190, -0.6957,  ...,  1.6021, -0.4632,  2.1589]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1825, -0.3662, -0.2765,  ...,  1.0684, -1.0255,  0.4294],\n",
      "          [-0.6892, -1.1335,  0.1937,  ...,  0.8420,  1.2524,  1.2455]],\n",
      "\n",
      "         [[ 0.0335,  0.5236, -0.9490,  ..., -0.1174, -1.8636,  0.8884],\n",
      "          [-2.2064, -1.6562,  0.7537,  ...,  0.9959, -0.2515,  1.5763]],\n",
      "\n",
      "         [[-0.8423, -0.6972, -0.9051,  ...,  0.2931, -0.7744, -0.1897],\n",
      "          [ 0.9456,  0.0344,  0.6242,  ...,  2.6278, -1.0854, -0.0061]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4644,  0.2643, -0.8147,  ...,  0.0692, -1.1281,  0.5858],\n",
      "          [-0.8043,  0.0484, -0.1762,  ...,  0.2508, -0.8680,  0.1852]],\n",
      "\n",
      "         [[-0.0356, -1.4995, -1.3971,  ...,  1.4830, -0.6459, -0.3064],\n",
      "          [-0.4609, -0.5825, -0.4957,  ...,  1.0448, -0.4089,  1.3863]],\n",
      "\n",
      "         [[-1.1003, -0.9609, -0.6742,  ...,  0.1590, -1.3803,  0.2803],\n",
      "          [ 0.1687, -1.9053, -1.0013,  ...,  1.7294, -0.5269,  2.1107]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.9418, -0.1090, -0.6614,  ...,  0.8747, -0.8836, -0.8742],\n",
      "          [-0.9999, -0.0289, -0.6231,  ...,  0.8722, -0.9996, -0.7898],\n",
      "          [-1.0014, -0.0776, -0.6223,  ...,  0.8620, -0.9143, -0.8197],\n",
      "          ...,\n",
      "          [-0.8956,  0.0242, -0.6181,  ...,  0.9038, -1.1124, -0.8189],\n",
      "          [-0.8915,  0.0105, -0.6161,  ...,  0.9337, -1.0429, -0.8551],\n",
      "          [-0.8243,  0.0390, -0.6416,  ...,  0.9110, -1.1088, -0.8276]],\n",
      "\n",
      "         [[-0.5328, -1.5265, -0.0820,  ...,  1.1230,  0.2675,  1.2164],\n",
      "          [-0.5188, -1.5580, -0.0175,  ...,  1.0738,  0.2053,  1.2384],\n",
      "          [-0.4976, -1.4941,  0.0686,  ...,  1.1243,  0.1860,  1.2535],\n",
      "          ...,\n",
      "          [-0.4501, -1.5178,  0.1567,  ...,  1.0563,  0.1723,  1.2185],\n",
      "          [-0.4767, -1.5266,  0.1568,  ...,  1.0673,  0.1547,  1.2086],\n",
      "          [-0.4237, -1.4804,  0.1917,  ...,  1.0723,  0.1616,  1.2312]]],\n",
      "\n",
      "\n",
      "        [[[-0.8609, -0.4423, -0.2441,  ...,  0.7282, -0.6501,  0.4750],\n",
      "          [-0.7126, -0.5264, -0.3840,  ...,  0.7319, -0.7236,  0.3708],\n",
      "          [-0.6883, -0.5079, -0.3949,  ...,  0.7693, -0.7422,  0.3456],\n",
      "          ...,\n",
      "          [-0.7206, -0.4905, -0.3995,  ...,  0.6934, -0.7716,  0.3610],\n",
      "          [-0.7015, -0.5028, -0.4164,  ...,  0.7215, -0.7481,  0.3460],\n",
      "          [-0.6215, -0.4933, -0.4762,  ...,  0.6920, -0.8418,  0.2799]],\n",
      "\n",
      "         [[-0.7427, -0.3960, -0.6602,  ...,  0.9431,  0.3752,  1.0017],\n",
      "          [-0.5515, -0.4112, -0.6060,  ...,  0.9926,  0.2137,  1.0240],\n",
      "          [-0.6406, -0.4475, -0.5213,  ...,  1.0049,  0.2063,  0.9823],\n",
      "          ...,\n",
      "          [-0.5380, -0.4561, -0.5056,  ...,  1.0728,  0.1582,  1.0076],\n",
      "          [-0.6400, -0.4109, -0.5897,  ...,  0.9516,  0.2875,  1.0004],\n",
      "          [-0.5773, -0.4152, -0.5359,  ...,  1.0098,  0.1712,  0.9837]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.9418, -0.1090, -0.6614,  ...,  0.8747, -0.8836, -0.8742],\n",
      "          [-0.5328, -1.5265, -0.0820,  ...,  1.1230,  0.2675,  1.2164]],\n",
      "\n",
      "         [[-0.9999, -0.0289, -0.6231,  ...,  0.8722, -0.9996, -0.7898],\n",
      "          [-0.5188, -1.5580, -0.0175,  ...,  1.0738,  0.2053,  1.2384]],\n",
      "\n",
      "         [[-1.0014, -0.0776, -0.6223,  ...,  0.8620, -0.9143, -0.8197],\n",
      "          [-0.4976, -1.4941,  0.0686,  ...,  1.1243,  0.1860,  1.2535]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8956,  0.0242, -0.6181,  ...,  0.9038, -1.1124, -0.8189],\n",
      "          [-0.4501, -1.5178,  0.1567,  ...,  1.0563,  0.1723,  1.2185]],\n",
      "\n",
      "         [[-0.8915,  0.0105, -0.6161,  ...,  0.9337, -1.0429, -0.8551],\n",
      "          [-0.4767, -1.5266,  0.1568,  ...,  1.0673,  0.1547,  1.2086]],\n",
      "\n",
      "         [[-0.8243,  0.0390, -0.6416,  ...,  0.9110, -1.1088, -0.8276],\n",
      "          [-0.4237, -1.4804,  0.1917,  ...,  1.0723,  0.1616,  1.2312]]],\n",
      "\n",
      "\n",
      "        [[[-0.8609, -0.4423, -0.2441,  ...,  0.7282, -0.6501,  0.4750],\n",
      "          [-0.7427, -0.3960, -0.6602,  ...,  0.9431,  0.3752,  1.0017]],\n",
      "\n",
      "         [[-0.7126, -0.5264, -0.3840,  ...,  0.7319, -0.7236,  0.3708],\n",
      "          [-0.5515, -0.4112, -0.6060,  ...,  0.9926,  0.2137,  1.0240]],\n",
      "\n",
      "         [[-0.6883, -0.5079, -0.3949,  ...,  0.7693, -0.7422,  0.3456],\n",
      "          [-0.6406, -0.4475, -0.5213,  ...,  1.0049,  0.2063,  0.9823]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7206, -0.4905, -0.3995,  ...,  0.6934, -0.7716,  0.3610],\n",
      "          [-0.5380, -0.4561, -0.5056,  ...,  1.0728,  0.1582,  1.0076]],\n",
      "\n",
      "         [[-0.7015, -0.5028, -0.4164,  ...,  0.7215, -0.7481,  0.3460],\n",
      "          [-0.6400, -0.4109, -0.5897,  ...,  0.9516,  0.2875,  1.0004]],\n",
      "\n",
      "         [[-0.6215, -0.4933, -0.4762,  ...,  0.6920, -0.8418,  0.2799],\n",
      "          [-0.5773, -0.4152, -0.5359,  ...,  1.0098,  0.1712,  0.9837]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "pipe = CompressionPipeline()\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = pipe(\n",
    "    mg,\n",
    "    pass_args={\n",
    "        \"quantize_transform_pass\": quantization_config,\n",
    "        \"prune_transform_pass\": pruning_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /vol/bitbucket/oa321/mase/tasks/tutorial5/t5_nas_compressed.pt, /vol/bitbucket/oa321/mase/tasks/tutorial5/t5_nas_compressed.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /vol/bitbucket/oa321/mase/tasks/tutorial5/t5_nas_compressed.pt\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Serialization of parametrized modules is only supported through state_dict(). See:\nhttps://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/t5_nas_compressed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/oa321/mase/src/chop/ir/graph/mase_graph.py:453\u001b[0m, in \u001b[0;36mMaseGraph.export\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    451\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExporting GraphModule to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 453\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExporting MaseMetadata to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    457\u001b[0m combined_meta \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/vol/bitbucket/oa321/mase/venv/lib/python3.11/site-packages/torch/serialization.py:944\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 944\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/vol/bitbucket/oa321/mase/venv/lib/python3.11/site-packages/torch/serialization.py:1190\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m persistent_id(obj)\n\u001b[1;32m   1189\u001b[0m pickler \u001b[38;5;241m=\u001b[39m PyTorchPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[0;32m-> 1190\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m   1192\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "File \u001b[0;32m/vol/bitbucket/oa321/mase/venv/lib/python3.11/site-packages/torch/nn/utils/parametrize.py:340\u001b[0m, in \u001b[0;36m_inject_new_class.<locals>.getstate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetstate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSerialization of parametrized modules is only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported through state_dict(). See:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/tutorials/beginner/saving_loading_models.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Serialization of parametrized modules is only supported through state_dict(). See:\nhttps://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training"
     ]
    }
   ],
   "source": [
    "mg.export(f\"{Path.cwd()}/t5_nas_compressed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
