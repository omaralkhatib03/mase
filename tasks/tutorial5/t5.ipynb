{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4, 8],\n",
    "    \"num_heads\": [2, 4, 8, 16],\n",
    "    \"hidden_size\": [128, 192, 256, 384, 512],\n",
    "    \"intermediate_size\": [512, 768, 1024, 1536, 2048],\n",
    "    \"linear_layer_choices\" : [\n",
    "        nn.Linear,\n",
    "        Identity\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "\n",
    "def construct_model(trial):\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    for param in [\n",
    "        \"num_layers\",\n",
    "        \"num_heads\",\n",
    "        \"hidden_size\",\n",
    "        \"intermediate_size\"\n",
    "    ]:\n",
    "        chosen_idex = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        setattr(config, param, search_space[param][chosen_idex])\n",
    "\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            new_layer_cls = trial.suggest_categorical(\n",
    "                f\"{name}_type\",\n",
    "                search_space[\"linear_layer_choices\"],\n",
    "            )\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()\n",
    "                deepsetattr(trial_model, name, new_layer)\n",
    "            else:\n",
    "                raise ValueError(f\"Unkown layer type: {new_layer_cls}\")\n",
    "\n",
    "    return trial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_trainer\n",
    "\n",
    "def objective(trial):\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model = model,\n",
    "        tokenized_dataset = dataset,\n",
    "        tokenizer = tokenizer,\n",
    "        evaluate_metric = \"accuracy\",\n",
    "        num_train_epochs = 1\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "\n",
    "sampler = RandomSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler\n",
    ")\n",
    "\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=1,\n",
    "    timeout=60*60*24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "model = study.best_trial.user_attrs[\"model\"].cpu()\n",
    "\n",
    "# print(Path.cwd())\n",
    "with open(f\"{Path.cwd()}/t5_best_model.pkl\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "pipe = CompressionPipeline()\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = pipe(\n",
    "    mg,\n",
    "    pass_args={\n",
    "        \"quantize_transform_pass\": quantization_config,\n",
    "        \"prune_transform_pass\": pruning_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.export(f\"{Path.cwd()}/t5_nas_compressed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
