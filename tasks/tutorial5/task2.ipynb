{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizsser_checkpoint,\n",
    "    return_tokenizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools import get_trainer\n",
    "\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "trainer = get_trainer(\n",
    "    model = model,\n",
    "    tokenized_dataset = dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    evaluate_metric = \"accuracy\",\n",
    "    num_train_epochs = 1\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "baseline = eval_results[\"eval_accuracy\"]\n",
    "print(baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4, 8],\n",
    "    \"num_heads\": [2, 4, 8, 16],\n",
    "    \"hidden_size\": [128, 192, 256, 384, 512],\n",
    "    \"intermediate_size\": [512, 768, 1024, 1536, 2048],\n",
    "    \"linear_layer_choices\" : [\"linear\", \"identity\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "\n",
    "track = set({})\n",
    "\n",
    "def construct_model(trial):\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "    config.problem_type = \"single_label_classification\"\n",
    "    ss_template = search_space\n",
    "\n",
    "    for param in [\n",
    "        \"num_layers\",\n",
    "        \"num_heads\",\n",
    "        \"hidden_size\",\n",
    "        \"intermediate_size\"\n",
    "    ]:\n",
    "        chosen_idex = trial.suggest_int(param, 0, len(ss_template[param]) - 1)\n",
    "        setattr(config, param, ss_template[param][chosen_idex])\n",
    "\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            track.add(name)\n",
    "            new_layer_cls = trial.suggest_categorical(\n",
    "                f\"{name}_type\",\n",
    "                ss_template[\"linear_layer_choices\"],\n",
    "            )\n",
    "\n",
    "            if new_layer_cls == \"linear\":\n",
    "                continue\n",
    "            elif new_layer_cls == \"identity\":\n",
    "                new_layer = Identity()\n",
    "                deepsetattr(trial_model, name, new_layer)\n",
    "            else:\n",
    "                raise ValueError(f\"Unkown layer type: {new_layer_cls}\")\n",
    "\n",
    "    return trial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_trainer\n",
    "\n",
    "def objective(trial):\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model = model,\n",
    "        tokenized_dataset = dataset,\n",
    "        tokenizer = tokenizer,\n",
    "        evaluate_metric = \"accuracy\",\n",
    "        num_train_epochs = 1\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Study\n",
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "\n",
    "def getGridSearchSpace():\n",
    "    grid_search_space = {\n",
    "        \"num_layers\": [i for i in range(0, len(search_space['num_layers']))],\n",
    "        \"num_heads\": [i for i in range(0, len(search_space['num_heads']))],\n",
    "        \"hidden_size\": [i for i in range(0, len(search_space['hidden_size']))],\n",
    "        \"intermediate_size\": [i for i in range(0, len(search_space['intermediate_size']))],\n",
    "    }\n",
    "\n",
    "    sampler = RandomSampler()\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        study_name=\"bert-tiny-nas-study\",\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "        lambda trial: construct_model(trial=trial),\n",
    "        n_trials = 100,\n",
    "        timeout=60*60*24\n",
    "    )\n",
    "\n",
    "    for name in track :\n",
    "        grid_search_space[f'{name}_type'] = [\"linear\", \"identity\"]\n",
    "\n",
    "    return grid_search_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler = GridSampler(search_space=getGridSearchSpace()) # The sampler to use below\n",
    "sampler = RandomSampler()\n",
    "# sampler = TPESampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials = 1,\n",
    "    timeout=60*60*24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "model = study.best_trial.user_attrs[\"model\"].cpu()\n",
    "\n",
    "with open(f\"{Path.home()}/mase/tasks/tutorial5/t5_best_model.pkl\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "pipe = CompressionPipeline()\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = pipe(\n",
    "    mg,\n",
    "    pass_args={\n",
    "        \"quantize_transform_pass\": quantization_config,\n",
    "        \"prune_transform_pass\": pruning_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from optuna import Study\n",
    "from optuna.trial import FrozenTrial\n",
    "\n",
    "def samplerTrial(sampler_name:str, trials:int, sampler, f=objective) -> None:\n",
    "\n",
    "    data = [0]*trials\n",
    "\n",
    "    def record_accuracy_callback(stud:Study, fzt:FrozenTrial):\n",
    "        print(f\"Trial: {fzt.number}, Accuracy: {fzt.value}\")\n",
    "        data[fzt.number-1] ={\"n\":fzt.number, \"accuracy\":fzt.value}\n",
    "\n",
    "    if (sampler == None):\n",
    "        raise RuntimeError(\"No Sampler Provided\")\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        study_name=f\"bert-tiny-nas-{sampler_name}-study\",\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "        f,\n",
    "        n_trials=trials,\n",
    "        timeout=60*60*24,\n",
    "        callbacks=[record_accuracy_callback]\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f\"{Path.home()}/mase/tasks/tutorial5/sampler_run_{sampler_name}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samplerTrial(sampler_name=\"grid\", trials=100, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "\n",
    "# df_r = pd.read_csv(f\"{Path.home()}/mase/tasks/tutorial5/random.csv\")\n",
    "# df_t = pd.read_csv(f\"{Path.home()}/mase/tasks/tutorial5/tpes.csv\")\n",
    "# df_g = pd.read_csv(f\"{Path.home()}/mase/tasks/tutorial5/grid.csv\")\n",
    "\n",
    "# # Function to compute cumulative max accuracy\n",
    "# def compute_cumulative_max(df):\n",
    "#     df_sorted = df.sort_values(by='n')\n",
    "#     df_sorted['max_accuracy'] = np.maximum.accumulate(df_sorted['accuracy'])\n",
    "#     return df_sorted\n",
    "\n",
    "# # Process data\n",
    "# df_r = compute_cumulative_max(df_r)\n",
    "# df_t = compute_cumulative_max(df_t)\n",
    "# df_g = compute_cumulative_max(df_g)\n",
    "\n",
    "# fig_pretrain = plt.figure(dpi=200)\n",
    "\n",
    "# plt.scatter(x=df_r['n'], y=df_r['max_accuracy'] * 100, marker='x', s=20)\n",
    "# plt.scatter(x=df_t['n'], y=df_t['max_accuracy'] * 100, marker='x', s=20)\n",
    "# plt.scatter(x=df_g['n'], y=df_g['max_accuracy'] * 100, marker='x', s=20)\n",
    "# plt.axhline(y=baseline * 100, linestyle='--', linewidth=0.8)\n",
    "# lgd = plt.legend(['Random Sampler', 'TPES Sampler', 'Grid Sampler', 'Baseline'], bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "# plt.xlabel(\"Trials\")\n",
    "# plt.ylabel(\"Accuracy %\")\n",
    "# plt.title(\"Trials vs Accuracy\")\n",
    "# plt.savefig(f\"{Path.home()}/mase/tasks/tutorial5/samplers\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chop.passes as passes\n",
    "\n",
    "trials = 2\n",
    "\n",
    "def objTrain(model, pre_evaluation=True):\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model = model,\n",
    "        tokenized_dataset = dataset,\n",
    "        tokenizer = tokenizer,\n",
    "        evaluate_metric = \"accuracy\",\n",
    "        num_train_epochs = 1\n",
    "    )\n",
    "\n",
    "    pre = {\"eval_accuracy\": 0 }\n",
    "\n",
    "    if (pre_evaluation):\n",
    "        pre = trainer.evaluate()\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    return pre[\"eval_accuracy\"], eval_results[\"eval_accuracy\"]\n",
    "\n",
    "data = [0] * trials\n",
    "\n",
    "def pipeObjective(trial):\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    mg = MaseGraph(\n",
    "        model,\n",
    "        hf_input_names=[\n",
    "            \"input_ids\",\n",
    "            \"attention_mask\",\n",
    "            \"labels\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "    mg, _ = passes.add_common_metadata_analysis_pass(mg)\n",
    "\n",
    "    _, post_t = objTrain(mg.model, False)\n",
    "\n",
    "    mg.model = mg.model.cpu()\n",
    "    quantization_config['by'] = \"type\"\n",
    "\n",
    "    mg, _ = pipe(\n",
    "            mg,\n",
    "            pass_args={\n",
    "                \"quantize_transform_pass\": quantization_config,\n",
    "                \"prune_transform_pass\": pruning_config,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    post_comp_no_t, eval_acc = objTrain(mg.model)\n",
    "\n",
    "    print(f\"Trial:{trial.number}, FstTrain: {post_t}, Compressa: {post_comp_no_t}, SndTrain: {eval_acc}\")\n",
    "\n",
    "    data[trial.number] = {\n",
    "        \"n\": trial.number,\n",
    "        \"fst_train\": post_t,\n",
    "        \"compress\": post_comp_no_t,\n",
    "        \"snd_train\": eval_acc\n",
    "    }\n",
    "\n",
    "    return eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=f\"bert-tiny-nas-study\",\n",
    "    sampler=sampler\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    pipeObjective,\n",
    "    n_trials=trials,\n",
    "    timeout=60*60*24\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f\"{Path.home()}/mase/tasks/tutorial5/random_cp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df_name:str) -> None:\n",
    "    df = pd.read_csv(f\"{Path.home()}/mase/tasks/tutorial5/{df_name}.csv\")\n",
    "\n",
    "    plt.scatter(x=df['n'], y=df['fst_train'] * 100, marker='x', s=20)\n",
    "    plt.scatter(x=df['n'], y=df['compress'] * 100, marker='x', s=20)\n",
    "    plt.scatter(x=df['n'], y=df['snd_train'] * 100, marker='x', s=20)\n",
    "    plt.axhline(y=baseline * 100, linestyle='--', linewidth=0.8)\n",
    "    plt.legend(['Pre-Compress', 'After Compressing', 'Post Compress Training', 'Baseline'], bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "    plt.xlabel(\"Trials\")\n",
    "    plt.ylabel(\"Accuracy %\")\n",
    "    plt.title(\"Trials vs Accuracy\")\n",
    "    plt.savefig(f\"{Path.home()}/mase/tasks/tutorial5/cp_{df_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# plot('random_cp_partial')\n",
    "# plot('tpes_cp')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mase_env]",
   "language": "python",
   "name": "conda-env-mase_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
